{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto_integrador_IIIB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guiaech/projeto-integrador-IIIB/blob/main/Projeto_integrador_IIIB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN133_Me1MmH"
      },
      "source": [
        "# **NLTK (Natural Language Toolkit)**\n",
        "\n",
        "Essa biblioteca contém pacotes para fazer com que as maquinas entendam a liguagem humana."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r04BB4aR1fSf",
        "outputId": "7b1be88e-710d-4800-fde3-209796afcb54"
      },
      "source": [
        "!pip install nltk #Instalando a biblioteca"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4OFwPn-1oD0",
        "outputId": "35e32f29-4471-490f-8465-ae8917203d91"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> all\n",
            "    Downloading collection 'all'\n",
            "       | \n",
            "       | Downloading package abc to /root/nltk_data...\n",
            "       |   Unzipping corpora/abc.zip.\n",
            "       | Downloading package alpino to /root/nltk_data...\n",
            "       |   Unzipping corpora/alpino.zip.\n",
            "       | Downloading package biocreative_ppi to /root/nltk_data...\n",
            "       |   Unzipping corpora/biocreative_ppi.zip.\n",
            "       | Downloading package brown to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown.zip.\n",
            "       | Downloading package brown_tei to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown_tei.zip.\n",
            "       | Downloading package cess_cat to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_cat.zip.\n",
            "       | Downloading package cess_esp to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_esp.zip.\n",
            "       | Downloading package chat80 to /root/nltk_data...\n",
            "       |   Unzipping corpora/chat80.zip.\n",
            "       | Downloading package city_database to /root/nltk_data...\n",
            "       |   Unzipping corpora/city_database.zip.\n",
            "       | Downloading package cmudict to /root/nltk_data...\n",
            "       |   Unzipping corpora/cmudict.zip.\n",
            "       | Downloading package comparative_sentences to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/comparative_sentences.zip.\n",
            "       | Downloading package comtrans to /root/nltk_data...\n",
            "       | Downloading package conll2000 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2000.zip.\n",
            "       | Downloading package conll2002 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2002.zip.\n",
            "       | Downloading package conll2007 to /root/nltk_data...\n",
            "       | Downloading package crubadan to /root/nltk_data...\n",
            "       |   Unzipping corpora/crubadan.zip.\n",
            "       | Downloading package dependency_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/dependency_treebank.zip.\n",
            "       | Downloading package dolch to /root/nltk_data...\n",
            "       |   Unzipping corpora/dolch.zip.\n",
            "       | Downloading package europarl_raw to /root/nltk_data...\n",
            "       |   Unzipping corpora/europarl_raw.zip.\n",
            "       | Downloading package floresta to /root/nltk_data...\n",
            "       |   Unzipping corpora/floresta.zip.\n",
            "       | Downloading package framenet_v15 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v15.zip.\n",
            "       | Downloading package framenet_v17 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v17.zip.\n",
            "       | Downloading package gazetteers to /root/nltk_data...\n",
            "       |   Unzipping corpora/gazetteers.zip.\n",
            "       | Downloading package genesis to /root/nltk_data...\n",
            "       |   Unzipping corpora/genesis.zip.\n",
            "       | Downloading package gutenberg to /root/nltk_data...\n",
            "       |   Unzipping corpora/gutenberg.zip.\n",
            "       | Downloading package ieer to /root/nltk_data...\n",
            "       |   Unzipping corpora/ieer.zip.\n",
            "       | Downloading package inaugural to /root/nltk_data...\n",
            "       |   Unzipping corpora/inaugural.zip.\n",
            "       | Downloading package indian to /root/nltk_data...\n",
            "       |   Unzipping corpora/indian.zip.\n",
            "       | Downloading package jeita to /root/nltk_data...\n",
            "       | Downloading package kimmo to /root/nltk_data...\n",
            "       |   Unzipping corpora/kimmo.zip.\n",
            "       | Downloading package knbc to /root/nltk_data...\n",
            "       | Downloading package lin_thesaurus to /root/nltk_data...\n",
            "       |   Unzipping corpora/lin_thesaurus.zip.\n",
            "       | Downloading package mac_morpho to /root/nltk_data...\n",
            "       |   Unzipping corpora/mac_morpho.zip.\n",
            "       | Downloading package machado to /root/nltk_data...\n",
            "       | Downloading package masc_tagged to /root/nltk_data...\n",
            "       | Downloading package moses_sample to /root/nltk_data...\n",
            "       |   Unzipping models/moses_sample.zip.\n",
            "       | Downloading package movie_reviews to /root/nltk_data...\n",
            "       |   Unzipping corpora/movie_reviews.zip.\n",
            "       | Downloading package names to /root/nltk_data...\n",
            "       |   Unzipping corpora/names.zip.\n",
            "       | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "       | Downloading package nps_chat to /root/nltk_data...\n",
            "       |   Unzipping corpora/nps_chat.zip.\n",
            "       | Downloading package omw to /root/nltk_data...\n",
            "       |   Unzipping corpora/omw.zip.\n",
            "       | Downloading package opinion_lexicon to /root/nltk_data...\n",
            "       |   Unzipping corpora/opinion_lexicon.zip.\n",
            "       | Downloading package paradigms to /root/nltk_data...\n",
            "       |   Unzipping corpora/paradigms.zip.\n",
            "       | Downloading package pil to /root/nltk_data...\n",
            "       |   Unzipping corpora/pil.zip.\n",
            "       | Downloading package pl196x to /root/nltk_data...\n",
            "       |   Unzipping corpora/pl196x.zip.\n",
            "       | Downloading package ppattach to /root/nltk_data...\n",
            "       |   Unzipping corpora/ppattach.zip.\n",
            "       | Downloading package problem_reports to /root/nltk_data...\n",
            "       |   Unzipping corpora/problem_reports.zip.\n",
            "       | Downloading package propbank to /root/nltk_data...\n",
            "       | Downloading package ptb to /root/nltk_data...\n",
            "       |   Unzipping corpora/ptb.zip.\n",
            "       | Downloading package product_reviews_1 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_1.zip.\n",
            "       | Downloading package product_reviews_2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_2.zip.\n",
            "       | Downloading package pros_cons to /root/nltk_data...\n",
            "       |   Unzipping corpora/pros_cons.zip.\n",
            "       | Downloading package qc to /root/nltk_data...\n",
            "       |   Unzipping corpora/qc.zip.\n",
            "       | Downloading package reuters to /root/nltk_data...\n",
            "       | Downloading package rte to /root/nltk_data...\n",
            "       |   Unzipping corpora/rte.zip.\n",
            "       | Downloading package semcor to /root/nltk_data...\n",
            "       | Downloading package senseval to /root/nltk_data...\n",
            "       |   Unzipping corpora/senseval.zip.\n",
            "       | Downloading package sentiwordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentiwordnet.zip.\n",
            "       | Downloading package sentence_polarity to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentence_polarity.zip.\n",
            "       | Downloading package shakespeare to /root/nltk_data...\n",
            "       |   Unzipping corpora/shakespeare.zip.\n",
            "       | Downloading package sinica_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/sinica_treebank.zip.\n",
            "       | Downloading package smultron to /root/nltk_data...\n",
            "       |   Unzipping corpora/smultron.zip.\n",
            "       | Downloading package state_union to /root/nltk_data...\n",
            "       |   Unzipping corpora/state_union.zip.\n",
            "       | Downloading package stopwords to /root/nltk_data...\n",
            "       |   Unzipping corpora/stopwords.zip.\n",
            "       | Downloading package subjectivity to /root/nltk_data...\n",
            "       |   Unzipping corpora/subjectivity.zip.\n",
            "       | Downloading package swadesh to /root/nltk_data...\n",
            "       |   Unzipping corpora/swadesh.zip.\n",
            "       | Downloading package switchboard to /root/nltk_data...\n",
            "       |   Unzipping corpora/switchboard.zip.\n",
            "       | Downloading package timit to /root/nltk_data...\n",
            "       |   Unzipping corpora/timit.zip.\n",
            "       | Downloading package toolbox to /root/nltk_data...\n",
            "       |   Unzipping corpora/toolbox.zip.\n",
            "       | Downloading package treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/treebank.zip.\n",
            "       | Downloading package twitter_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/twitter_samples.zip.\n",
            "       | Downloading package udhr to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr.zip.\n",
            "       | Downloading package udhr2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr2.zip.\n",
            "       | Downloading package unicode_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/unicode_samples.zip.\n",
            "       | Downloading package universal_treebanks_v20 to\n",
            "       |     /root/nltk_data...\n",
            "       | Downloading package verbnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet.zip.\n",
            "       | Downloading package verbnet3 to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet3.zip.\n",
            "       | Downloading package webtext to /root/nltk_data...\n",
            "       |   Unzipping corpora/webtext.zip.\n",
            "       | Downloading package wordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet.zip.\n",
            "       | Downloading package wordnet31 to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet31.zip.\n",
            "       | Downloading package wordnet_ic to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet_ic.zip.\n",
            "       | Downloading package words to /root/nltk_data...\n",
            "       |   Unzipping corpora/words.zip.\n",
            "       | Downloading package ycoe to /root/nltk_data...\n",
            "       |   Unzipping corpora/ycoe.zip.\n",
            "       | Downloading package rslp to /root/nltk_data...\n",
            "       |   Unzipping stemmers/rslp.zip.\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "       | Downloading package universal_tagset to /root/nltk_data...\n",
            "       |   Unzipping taggers/universal_tagset.zip.\n",
            "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "       | Downloading package punkt to /root/nltk_data...\n",
            "       |   Unzipping tokenizers/punkt.zip.\n",
            "       | Downloading package book_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/book_grammars.zip.\n",
            "       | Downloading package sample_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/sample_grammars.zip.\n",
            "       | Downloading package spanish_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/spanish_grammars.zip.\n",
            "       | Downloading package basque_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/basque_grammars.zip.\n",
            "       | Downloading package large_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/large_grammars.zip.\n",
            "       | Downloading package tagsets to /root/nltk_data...\n",
            "       |   Unzipping help/tagsets.zip.\n",
            "       | Downloading package snowball_data to /root/nltk_data...\n",
            "       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n",
            "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "       | Downloading package word2vec_sample to /root/nltk_data...\n",
            "       |   Unzipping models/word2vec_sample.zip.\n",
            "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
            "       | Downloading package mte_teip5 to /root/nltk_data...\n",
            "       |   Unzipping corpora/mte_teip5.zip.\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "       | Downloading package averaged_perceptron_tagger_ru to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
            "       | Downloading package perluniprops to /root/nltk_data...\n",
            "       |   Unzipping misc/perluniprops.zip.\n",
            "       | Downloading package nonbreaking_prefixes to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "       | Downloading package vader_lexicon to /root/nltk_data...\n",
            "       | Downloading package porter_test to /root/nltk_data...\n",
            "       |   Unzipping stemmers/porter_test.zip.\n",
            "       | Downloading package wmt15_eval to /root/nltk_data...\n",
            "       |   Unzipping models/wmt15_eval.zip.\n",
            "       | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "       |   Unzipping misc/mwa_ppdb.zip.\n",
            "       | \n",
            "     Done downloading collection all\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD4YY_wxCOoK"
      },
      "source": [
        "# **Criando o modelo para classificar os tweets em positivo, negativo ou neutro.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToB_4uTgPaHh"
      },
      "source": [
        "# Importando as bibliotecas que iremos utilizar:\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVx3OtuGESJf"
      },
      "source": [
        "classificados = pd.read_csv('tweets_classificados.csv') #Abrindo arquivo csv e definindo como objeto com dados já classificados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLz6y6Q1XHI_",
        "outputId": "c1be7a49-7567-4441-eff4-57097881ff11"
      },
      "source": [
        "classificados.Classificacao.value_counts()  #verificando a quantidade de dados classificados com cada sentimento"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positivo    3300\n",
              "Neutro      2453\n",
              "Negativo    2446\n",
              "Name: Classificacao, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "4xP1SLlwcGZz",
        "outputId": "061b03d6-6b9f-42b2-a19e-5186006f3dea"
      },
      "source": [
        "classificados.Classificacao.value_counts().plot(kind='bar') #Gerando um grafico de barras com os dados classificados com cada sentimento"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f54b42d3210>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlVws98scVmy",
        "outputId": "814306e0-bc5e-405e-c79e-99aa2aa8d409"
      },
      "source": [
        "#Observando o tamanho do Data Frame\n",
        "classificados.Text.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8199"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqeNWsnodCoH"
      },
      "source": [
        "#Remover os dados repetidos como os ReTweets\n",
        "classificados.drop_duplicates(['Text'], inplace=True) #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3mleHXadSN8",
        "outputId": "598e5658-8ac5-4a45-9bf1-a42d085eef6d"
      },
      "source": [
        "#Observando o tamanho do Data Frame\n",
        "classificados.Text.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5765"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTsawRhidTOs"
      },
      "source": [
        "# Separando texto e suas classes:\n",
        "texto = classificados['Text']\n",
        "classes = classificados['Classificacao']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2il3AC-hSy54"
      },
      "source": [
        "# **Stopwords**\n",
        "\n",
        " . São palavras e termos frequentes porém que não possuem relevância nas sentenças\n",
        "\n",
        ". Exemplos: as, os, um, com, de, da, para, etc...\n",
        "\n",
        ". O nltk possui uma lista de stopwords em 16 idiomas diferentes. Vamos criar função que remova todas as stopwords em POrtuguês.\n",
        "\n",
        "# **Remove caracteres indesejados como links...**\n",
        "\n",
        "\n",
        "Essa etapa é para retirar dados indesejados que não trazem nenhuma informação\\"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nYnCEKbeOs6"
      },
      "source": [
        "def Preprocessing(instancia):\n",
        "     instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','').replace('\"','')\n",
        "     stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
        "     palavras = [i for i in instancia.split() if not i in stopwords]\n",
        "     return (\" \".join(palavras))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKbd5GjKjbfF"
      },
      "source": [
        "# Aplica a função em todos os dados:\n",
        "from nltk.corpus import stopwords\n",
        "texto = [Preprocessing(i) for i in texto]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nMX1iUJjj5m",
        "outputId": "363ccc23-fb9d-49a8-8617-b834b0bd4191"
      },
      "source": [
        "texto[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['���⛪ @ catedral santo antônio governador valadares/mg',\n",
              " '� @ governador valadares, minas gerais',\n",
              " '�� @ governador valadares, minas gerais',\n",
              " '���',\n",
              " '��� psol vai questionar aumento vereadores prefeito bh justiça politica estado minas',\n",
              " 'bom bandido morto deputado cabo júlio condenado fica inelegível 10 anos politica estado minas',\n",
              " '25% mineiros dizem torcer time nenhum,mesmo dentro estado atléticomg cruzeiro pq?',\n",
              " 'gigantesca barba mal destaque caderno cultura estado minas',\n",
              " 'bb governo minas travam disputa sobre depósitos judiciais',\n",
              " 'vcs bh fica pequena! belo horizonte (pron [bɛloɾiˈzõntʃi][10] capital estado mg, área aproximadamente 331 km²']"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14WD_bA5SmCi"
      },
      "source": [
        "# **Tokenização**\n",
        "\n",
        "É o processo de tokenizar é pegar as strings e dividir em uma lista de tokens.\n",
        "\n",
        "Exemplo : Aprendendo Data Science para valer\n",
        "\n",
        "Fica : [ 'Aprendendo' , 'Data', 'Science' , 'para', 'valer']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45DII3A5lsv9"
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tweet_tokenizer = TweetTokenizer() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFFNEuCHRqdi"
      },
      "source": [
        "# Instancia o objeto que faz a vetorização dos dados de texto:\n",
        "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KL7BIWVl-BW",
        "outputId": "964b7e0b-f9fe-42e2-969b-85023e201bee"
      },
      "source": [
        "# Aplica o vetorizador nos dados de texto e retorna uma matriz esparsa ( contendo vários zeros):\n",
        "freq_tweets = vectorizer.fit_transform(texto)\n",
        "type(freq_tweets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh-1-R2TmECS",
        "outputId": "4ac90a31-fade-4fcf-8ab5-0dcc34ef8377"
      },
      "source": [
        "# Visualizando o número de linhas e colunas da matriz:\n",
        "freq_tweets.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5765, 7336)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6vEdNdYmG0H",
        "outputId": "4249a66b-3382-4449-e680-597893b9f34f"
      },
      "source": [
        "# Treino de modelo de Machine Learning:\n",
        "modelo = MultinomialNB()\n",
        "modelo.fit(freq_tweets,classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5RcoaQymL7R"
      },
      "source": [
        "# Defina instâncias de teste dentro de uma lista:\n",
        "testes = ['Esse governo está no início, vamos ver o que vai dar',\n",
        "          'Estou muito feliz com o governo de Minas esse ano',\n",
        "          'O estado de Minas Gerais decretou calamidade financeira!!!',\n",
        "          'A segurança desse país está deixando a desejar',\n",
        "          'O governador de Minas é mais uma vez do PT']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu179QxtmQTu"
      },
      "source": [
        "# Transforma os dados de teste em vetores de palavras:\n",
        "freq_testes = vectorizer.transform(testes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o7BJuvlmWrz",
        "outputId": "9f8f3a1b-1f77-44eb-dc6b-1dc4f1e8124f"
      },
      "source": [
        "# Fazendo a classificação com o modelo treinado:\n",
        "for t, c in zip (testes,modelo.predict(freq_testes)):\n",
        "    # t representa o tweet e c a classificação de cada tweet.\n",
        "    print (t +\", \"+ c) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Esse governo está no início, vamos ver o que vai dar, Negativo\n",
            "Estou muito feliz com o governo de Minas esse ano, Neutro\n",
            "O estado de Minas Gerais decretou calamidade financeira!!!, Negativo\n",
            "A segurança desse país está deixando a desejar, Neutro\n",
            "O governador de Minas é mais uma vez do PT, Neutro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtkZlPnnmpAU",
        "outputId": "00907688-b2d0-49ab-89e8-11ce66d889b0"
      },
      "source": [
        "# Probabilidades de cada classe:\n",
        "print (modelo.classes_)\n",
        "modelo.predict_proba(freq_testes).round(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Negativo' 'Neutro' 'Positivo']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.68, 0.32, 0.  ],\n",
              "       [0.12, 0.84, 0.04],\n",
              "       [0.99, 0.01, 0.  ],\n",
              "       [0.36, 0.64, 0.  ],\n",
              "       [0.1 , 0.9 , 0.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzNz4f_0mw9U"
      },
      "source": [
        "# Função para aplicar as tags de negação:\n",
        "def marque_negacao(texto):\n",
        "    negacoes = ['não','not']\n",
        "    negacao_detectada = False\n",
        "    resultado = []\n",
        "    palavras = texto.split()\n",
        "    for p in palavras:\n",
        "        p = p.lower()\n",
        "        if negacao_detectada == True:\n",
        "            p = p + '_NEG'\n",
        "        if p in negacoes:\n",
        "            negacao_detectada = True\n",
        "        resultado.append(p)\n",
        "    return (\" \".join(resultado))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQsb7n_Em0ew",
        "outputId": "7bec33f9-dab8-4592-8612-63bb1ecd5d0d"
      },
      "source": [
        "# Vetorizando os dados e passando o classificador:\n",
        "from sklearn.pipeline import Pipeline\n",
        "pipeline_simples = Pipeline([\n",
        "  ('counts', CountVectorizer()),\n",
        "  ('classifier', MultinomialNB())\n",
        "])\n",
        "pipeline_simples.fit(texto,classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('counts', CountVectorizer()), ('classifier', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCg0uZRRm5va",
        "outputId": "c172438a-bc17-473f-8468-600d15dfa955"
      },
      "source": [
        "# Pipeline que atribui tag de negações nas palavras:\n",
        "pipeline_negacoes = Pipeline([\n",
        "  ('counts', CountVectorizer(tokenizer=lambda text: marque_negacao(text))),\n",
        "  ('classifier', MultinomialNB())\n",
        "])\n",
        "pipeline_negacoes.fit(texto,classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('counts',\n",
              "                 CountVectorizer(tokenizer=<function <lambda> at 0x7f54bacb4440>)),\n",
              "                ('classifier', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEVn0Vsym9Ip"
      },
      "source": [
        "# Pipeline simples:\n",
        "pipeline_svm_simples = Pipeline([\n",
        "  ('counts', CountVectorizer()),\n",
        "  ('classifier', svm.SVC(kernel='linear'))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL9Rq06Cm_1j"
      },
      "source": [
        "# Pipeline com tag de negação:\n",
        "pipeline_svm_negacoes = Pipeline([\n",
        "  ('counts', CountVectorizer(tokenizer=lambda text: marque_negacao(text))),\n",
        "  ('classifier', svm.SVC(kernel='linear'))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pKlUd-RnDIP"
      },
      "source": [
        "# Fazendo o cross validation do modelo:\n",
        "resultados = cross_val_predict(pipeline_simples, texto, classes, cv=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJFibXjmnIiB",
        "outputId": "70c5b749-088b-488d-b2a8-270eed85bedb"
      },
      "source": [
        "# Medindo a acurácia média do modelo:\n",
        "metrics.accuracy_score(classes,resultados)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8742411101474414"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2andW05nLEZ",
        "outputId": "4140d28f-9908-41d6-b733-19bfae3829d2"
      },
      "source": [
        "# Matriz de confusão:\n",
        "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predito   Negativo  Neutro  Positivo   All\n",
            "Real                                      \n",
            "Negativo       852      94         5   951\n",
            "Neutro         205    1675        94  1974\n",
            "Positivo        55     272      2513  2840\n",
            "All           1112    2041      2612  5765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXveK8nBoWTA",
        "outputId": "bbbaafe8-36d3-4a53-e4ba-f0b3a7dc8671"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Medidas de validação do modelo:\n",
        "sentimento=['Positivo','Negativo','Neutro']\n",
        "print (metrics.classification_report(classes,resultados))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negativo       0.77      0.90      0.83       951\n",
            "      Neutro       0.82      0.85      0.83      1974\n",
            "    Positivo       0.96      0.88      0.92      2840\n",
            "\n",
            "    accuracy                           0.87      5765\n",
            "   macro avg       0.85      0.88      0.86      5765\n",
            "weighted avg       0.88      0.87      0.88      5765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KQNQsj4pI1l"
      },
      "source": [
        "# Função para automatizar todo o processo acima:\n",
        "def Metricas(modelo, tweets, classes):\n",
        "  resultados = cross_val_predict(modelo, tweets, classes, cv=10)\n",
        "  return 'Acurácia do modelo: {}'.format(metrics.accuracy_score(classes,resultados))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MGuOgIX7pSHp",
        "outputId": "9d58c6d4-21e3-4f1b-f601-5fe607f453d7"
      },
      "source": [
        "# Naive Bayes simples:\n",
        "Metricas(pipeline_simples,texto,classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Acurácia do modelo: 0.8742411101474414'"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9I0wz51ApX7G",
        "outputId": "4b11f7bd-0bbf-4e36-afc1-d3719361fbff"
      },
      "source": [
        "# Naive Bayes com tag de negacoes:\n",
        "Metricas(pipeline_negacoes,texto,classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Acurácia do modelo: 0.6905464006938421'"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "m-ygvakipccX",
        "outputId": "0adf8976-495b-49aa-faec-5a8f1b343280"
      },
      "source": [
        "# SVM linear simples:\n",
        "Metricas(pipeline_svm_simples,texto,classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Acurácia do modelo: 0.8863833477883781'"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WPm1MSjMpiCz",
        "outputId": "b4ef30b0-2408-475b-92a2-75bfc604b3d1"
      },
      "source": [
        "# SVM linear com tag de negacoes:\n",
        "Metricas(pipeline_svm_negacoes,texto,classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Acurácia do modelo: 0.7457068516912403'"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i0wyFkip4QR"
      },
      "source": [
        "# Cross validation:\n",
        "resultados = cross_val_predict(pipeline_negacoes, texto, classes, cv=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WP10ggnp8Ct",
        "outputId": "4d444bd9-e6ca-4595-8e40-6c4ccddfc353"
      },
      "source": [
        "# Medindo a acurácia do modelo:\n",
        "metrics.accuracy_score(classes,resultados)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6905464006938421"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dPEwkhnp_Wt",
        "outputId": "3df0eed4-9f2b-42a2-9d51-3b2c175502f3"
      },
      "source": [
        "# Medidas de validação do modelo:\n",
        "print (metrics.classification_report(classes,resultados))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negativo       0.68      0.52      0.59       951\n",
            "      Neutro       0.66      0.58      0.61      1974\n",
            "    Positivo       0.71      0.83      0.76      2840\n",
            "\n",
            "    accuracy                           0.69      5765\n",
            "   macro avg       0.68      0.64      0.66      5765\n",
            "weighted avg       0.69      0.69      0.68      5765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Tf0Oo6GqHot",
        "outputId": "2f3ee7fa-afea-44d5-9b1b-c389d9be60e4"
      },
      "source": [
        "# Matriz de confusão:\n",
        "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predito   Negativo  Neutro  Positivo   All\n",
            "Real                                      \n",
            "Negativo       492     177       282   951\n",
            "Neutro         151    1136       687  1974\n",
            "Positivo        79     408      2353  2840\n",
            "All            722    1721      3322  5765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv-SkrpUTmrW"
      },
      "source": [
        "# **Consumindo tweets reais para analisar com o algoritmo já treinado**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qrp5Tf3GA-o",
        "outputId": "8632f811-891c-445d-d560-18d0a6edc47e"
      },
      "source": [
        "#Instalação da biblioteca\n",
        "!pip install TwitterSearch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: TwitterSearch in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: requests>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from TwitterSearch) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from TwitterSearch) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->TwitterSearch) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->TwitterSearch) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->TwitterSearch) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->TwitterSearch) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.3.0->TwitterSearch) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz7J05EBNs86"
      },
      "source": [
        "#Importação das bibliotecas\n",
        "from datetime import datetime\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfXM3vylN9K-"
      },
      "source": [
        "#Definindo as chaves fornecidas pelo twitter para consumo da API\n",
        "consumer_key = 'IMJh4kjQLGDzUaT9t1v0RXm5Y'\n",
        "consumer_secret = 'cjt9d684CpvElXof1BxUMgSakNnFBVLDweQTSpGZolzzrnU8JE'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpR2lzftOFRi"
      },
      "source": [
        "#Definindo os tokens fornecidos pelo twitter para consumo da API\n",
        "access_token = '968521944944529408-oI5NcJVaZellwrsPjhsQkQPDeAZJzKf'\n",
        "access_token_secret = 'hc7bTI65fG97smD3ZEB6iCjLrBzHBxn2Sp6TIaX8fZSJZ'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYvGKI20GYYC"
      },
      "source": [
        "from TwitterSearch import *                                                                                          #Importando a biblioteca para consumo da API do Twitter\n",
        "try:\n",
        "\n",
        "    ts = TwitterSearch(                                                                                              #Objeto TwitterSearch object\n",
        "        consumer_key = consumer_key,\n",
        "        consumer_secret = consumer_secret,\n",
        "        access_token = access_token,\n",
        "        access_token_secret = access_token_secret\n",
        "     )\n",
        "\n",
        "    tso = TwitterSearchOrder()                                                                                        #Criando o objeto TwitterSearchOrder\n",
        "    tso.set_keywords(['lula'], or_operator = True)                                                                    #Definindo as palavras chaves para a pesquisa\n",
        "    tso.set_language('pt')                                                                                            #Definindo a língua a ser pesquisada\n",
        "\n",
        "    for tweet in ts.search_tweets_iterable(tso):                                                                      # ts.search_tweets_iterable(tso) é um metadata\n",
        "        print( 'created_at: ', tweet['created_at'], 'User_id: ', tweet['id_str'], 'Tweet: ', tweet['text']  )         #Definindo quais atributos serão mostrados\n",
        "        created_at = tweet['created_at']\n",
        "        user_id = tweet['id_str']\n",
        "        texto = tweet['text']\n",
        "\n",
        "        with open(\"tweet.json\", \"a+\") as output:                                                                      #Criando arquivo JSON para recebimento dos dados\n",
        "\n",
        "          data = {\n",
        "              \"created_at\": created_at,\n",
        "              \"User_id\": user_id,\n",
        "              \"tweet\": texto\n",
        "          }\n",
        "          output.write(\"{}\\n\".format(json.dumps(data)))                                                                #Preenchendo os dados no arquivo JSON\n",
        "\n",
        "except TwitterSearchException as e:\n",
        "    print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "v-rB8jIkIZIS",
        "outputId": "54f2c05b-2094-4fa0-843d-4290502113af"
      },
      "source": [
        "import pandas as pd                                                             #Importando biblioteca\n",
        "df = pd.read_json('tweet.json', lines = True)                                   #Definindo variavel para receber o arquivo JSON\n",
        "df.head(10)                                                                     #Abrindo as 10 primeiras linhas do arquivo JSON"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>User_id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-11-28 11:34:38+00:00</td>\n",
              "      <td>1464920666130554880</td>\n",
              "      <td>RT @FrankCastle2009: VC CONHECE UM POBRE QUE S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-11-28 11:34:37+00:00</td>\n",
              "      <td>1464920663643373568</td>\n",
              "      <td>RT @TCelTitoCanto: Deixa eu ver se entendi. O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-11-28 11:34:36+00:00</td>\n",
              "      <td>1464920657200828416</td>\n",
              "      <td>RT @AttuchLeonardo: O capital e as eleições em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-11-28 11:34:34+00:00</td>\n",
              "      <td>1464920651454631936</td>\n",
              "      <td>RT @gustavocastanon: Agora temos Bozo, Lula, M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-11-28 11:34:34+00:00</td>\n",
              "      <td>1464920649118408704</td>\n",
              "      <td>RT @oiIuiz: Sim, mas os caras não te deixam gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2021-11-28 11:34:32+00:00</td>\n",
              "      <td>1464920641644240896</td>\n",
              "      <td>@Rodrigues3568 @camargo_jobson Vcs sempre usam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2021-11-28 11:34:29+00:00</td>\n",
              "      <td>1464920630457999360</td>\n",
              "      <td>@folha Kkkkkkkkk olha o Lula ai https://t.co/m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2021-11-28 11:34:29+00:00</td>\n",
              "      <td>1464920627287109632</td>\n",
              "      <td>RT @renatosimoespt: \"Em encontro com evangélic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2021-11-28 11:34:28+00:00</td>\n",
              "      <td>1464920624107864064</td>\n",
              "      <td>RT @ptbrasil: 🤳🏾A presença do ex-presidente Lu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2021-11-28 11:34:28+00:00</td>\n",
              "      <td>1464920623898107904</td>\n",
              "      <td>RT @anacronices: lula: abertura do fórum socia...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 created_at  ...                                              tweet\n",
              "0 2021-11-28 11:34:38+00:00  ...  RT @FrankCastle2009: VC CONHECE UM POBRE QUE S...\n",
              "1 2021-11-28 11:34:37+00:00  ...  RT @TCelTitoCanto: Deixa eu ver se entendi. O ...\n",
              "2 2021-11-28 11:34:36+00:00  ...  RT @AttuchLeonardo: O capital e as eleições em...\n",
              "3 2021-11-28 11:34:34+00:00  ...  RT @gustavocastanon: Agora temos Bozo, Lula, M...\n",
              "4 2021-11-28 11:34:34+00:00  ...  RT @oiIuiz: Sim, mas os caras não te deixam gr...\n",
              "5 2021-11-28 11:34:32+00:00  ...  @Rodrigues3568 @camargo_jobson Vcs sempre usam...\n",
              "6 2021-11-28 11:34:29+00:00  ...  @folha Kkkkkkkkk olha o Lula ai https://t.co/m...\n",
              "7 2021-11-28 11:34:29+00:00  ...  RT @renatosimoespt: \"Em encontro com evangélic...\n",
              "8 2021-11-28 11:34:28+00:00  ...  RT @ptbrasil: 🤳🏾A presença do ex-presidente Lu...\n",
              "9 2021-11-28 11:34:28+00:00  ...  RT @anacronices: lula: abertura do fórum socia...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSIXIf3tVUX8"
      },
      "source": [
        "lula = df['tweet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6ropYQKVr5q",
        "outputId": "c5758590-6c03-42e6-e90c-47c7412bd5b8"
      },
      "source": [
        "lula"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        RT @FrankCastle2009: VC CONHECE UM POBRE QUE S...\n",
              "1        RT @TCelTitoCanto: Deixa eu ver se entendi. O ...\n",
              "2        RT @AttuchLeonardo: O capital e as eleições em...\n",
              "3        RT @gustavocastanon: Agora temos Bozo, Lula, M...\n",
              "4        RT @oiIuiz: Sim, mas os caras não te deixam gr...\n",
              "                               ...                        \n",
              "23891    RT @ThiagoResiste: Agora que Lula ganhou tudo ...\n",
              "23892    @diogomainardi @Miltonneves Resposta fácil 25%...\n",
              "23893    RT @Alexand92840726: A exatos 316 dias para ir...\n",
              "23894    @FrankCastle2009 Sim, a Marisa Letícia, ainda ...\n",
              "23895    @palmeriodoria ALÔ BRASIL.\\nAGORA É LULA! http...\n",
              "Name: tweet, Length: 23896, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNUlHIPvV134"
      },
      "source": [
        "lula = [Preprocessing(i) for i in lula]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKH6gYUeV-MQ",
        "outputId": "1e6a6a14-ce94-4a66-ba17-874a2bb1fbcd"
      },
      "source": [
        "lula[ :30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rt @frankcastle2009 vc conhece pobre saiu pobreza ajuda lula, pt esquerda????',\n",
              " 'rt @tceltitocanto deixa ver entendi stf desbloqueou lula bens lula?🤔🤔🤔',\n",
              " 'rt @attuchleonardo capital eleições 2022 (1 bolsonaro mantém parcela radical agronegócio (2 moro fica fatia…',\n",
              " 'rt @gustavocastanon agora bozo, lula, moro doria acotovelando executar projeto lutando debate econômico s…',\n",
              " 'rt @oiiuiz sim, caras deixam gritar hoje escolhidos lula dilma',\n",
              " '@rodrigues3568 @camargo_jobson vcs sempre usam narrativa vai site kkk ué candidato vcs deveria…',\n",
              " '@folha kkkkkkkkk olha lula ai',\n",
              " 'rt @renatosimoespt encontro evangélic@s, lula disse extraordinária relação todas igrejas governou distinção…',\n",
              " 'rt @ptbrasil 🤳🏾a presença expresidente lula redes sociais cresceu últimos meses, acordo pesquisa consultoria digital…',\n",
              " 'rt @anacronices lula abertura fórum social mundial sergio moro mesa redonda mbl',\n",
              " 'rt @lulaoficial encontro lula evangélicos',\n",
              " '@stf_oficial tudo ladrão !! @gilmarmendes covarde foge velhinhas gosta gritar fo…',\n",
              " '@stecilda11 @2018edu @ticostacruz prendeu lula sozinho, todos cooperaram pois q interessa grande bu…',\n",
              " 'rt @gnatalini reinaldo azevedo, homem criou conceito petralhas, defendendo lula/pt forma assombrosa mundo da…',\n",
              " '@sisuper1000 tática caras agora dividir voto direita, vota nele nova esquerda (mbl/psol…',\n",
              " 'rt @anacronices lula abertura fórum social mundial sergio moro mesa redonda mbl',\n",
              " '@pauloteixeira13 agora lula faz parceria alkmin vai sair partido',\n",
              " 'rt @marcelopintoba lula fará parte mesa abertura fórum social mundial 2022',\n",
              " 'rt @carlosefilho votarei dória incomodam dizem ser futuro 5° lugar farei campanha, tentarei convencer ninguém…',\n",
              " 'rt @jorgedomar todos candidatos subcandidatos, atacam @lulaoficial pois sabem militancia, redes, vai contestar e, assim, g…',\n",
              " 'rt @letcesar expectativa frente ampla antibolsonaro realidade frente ampla antilula',\n",
              " 'rt @celinaschmidt mundo precisa governança global disse lula lula outro patamar político relação qualque…',\n",
              " 'rt @oiiuiz sim, caras deixam gritar hoje escolhidos lula dilma',\n",
              " '@marcosalves_l @reginaldofiloso @ecantanhede boquirroto diz aonde dinheiro d9z 1ue lula roubou? o…',\n",
              " '@valbraz @atreyu_sc @ticostacruz criam umas teses tão malucas acreditam lula bandido doença demais',\n",
              " 'rt @zellflorizel bancos reunião clandestina deltan xp 2018 falar eleições presidenciais lava jato tirou lula…',\n",
              " 'rt @jornaldacidadeo primeira vez, bolsonaro faz revelação sobre macron lula (veja vídeo',\n",
              " 'rt @hilde_angel mote vez candidatos todos fomedesempregodesigualdade, básico antes, falavam economia inflação,…',\n",
              " 'rt @antjheroi hoje mal perdeu mal venceu',\n",
              " 'rt @kimpaim sabe decisão moro saiu defesa fachin? decisão tornou lula elegível? decisão permitiu…']"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coTGHHskdf4f",
        "outputId": "44904b30-11eb-4f22-e8f2-3c15cac6e9eb"
      },
      "source": [
        "lula_tweets = vectorizer.fit_transform(lula)\n",
        "type(lula_tweets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79e1MdKRdpeb",
        "outputId": "78e7bddb-1956-4955-e11c-b4ceb0ebfeb6"
      },
      "source": [
        "lula_tweets.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23896, 14489)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    }
  ]
}